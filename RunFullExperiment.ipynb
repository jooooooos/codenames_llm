{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9a4f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "import benchmark\n",
    "import llm_agent\n",
    "from llm_providers import create_llm\n",
    "from persona_loader import list_persona_ids\n",
    "\n",
    "importlib.reload(benchmark)\n",
    "importlib.reload(llm_agent)\n",
    "\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "# Paste your token inside the quotes\n",
    "login(HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54841dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MODEL CONFIGURATION =====\n",
    "# Choose which model to use by setting MODEL_CHOICE\n",
    "# Options: \"llama31\", \"mistral\", \"gemma2\"\n",
    "\n",
    "MODEL_CHOICE = \"gemma2\"  # Change this to switch models\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"llama31\": {\n",
    "        \"type\": \"local_hf\",\n",
    "        \"model_name\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \"temperature\": 0.6,\n",
    "        \"max_tokens\": 1024,\n",
    "        # \"load_in_4bit\": True\n",
    "    },\n",
    "    \"mistral\": {\n",
    "        \"type\": \"local_hf\",\n",
    "        \"model_name\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"temperature\": 0.7,\n",
    "        # \"load_in_4bit\": True\n",
    "    },\n",
    "    \"gemma2\": {\n",
    "        \"type\": \"local_hf\",\n",
    "        \"model_name\": \"google/gemma-2-9b-it\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2048,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d779e",
   "metadata": {},
   "source": [
    "## Full Persona Experiment\n",
    "\n",
    "This cell runs the complete experiment: all 441 combinations of personas (21 x 21, including None) with 5 games each.\n",
    "\n",
    "**⚠️ WARNING**: This will run **2,205 games** total and may take **many hours** depending on your model and hardware.\n",
    "\n",
    "**Features:**\n",
    "- Runs all combinations: (None, \"1\", ..., \"20\") x (None, \"1\", ..., \"20\")\n",
    "- 5 games per combination for statistical significance\n",
    "- **Saves intermediate results** after each combination (every 5 games)\n",
    "- Progress tracking with time estimates\n",
    "- Crash-resistant: can resume from intermediate results\n",
    "- All results saved to `experiment_results/{experiment_name}/`\n",
    "\n",
    "**Before running:**\n",
    "1. Make sure you have enough disk space (~500MB-1GB for all results)\n",
    "2. Consider starting with a smaller test run first\n",
    "3. Monitor the progress output to estimate total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd374e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  STARTING FULL EXPERIMENT - This will take a long time!\n",
      "Configuration:\n",
      "  - Model: google/gemma-2-9b-it\n",
      "  - Games per combination: 1\n",
      "  - Total games: 441\n",
      "  - Persona sharing: Enabled\n",
      "\n",
      "Results will be saved to: experiment_results/\n",
      "Intermediate results saved after each combination.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e226d9e0b646e89a187c742ddc864c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 21:33:36,720 [WARNING] Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING FULL PERSONA EXPERIMENT: full_persona_exp_20251118_213336\n",
      "================================================================================\n",
      "Model: google/gemma-2-9b-it\n",
      "Persona IDs: 21 (None + 1-20)\n",
      "Combinations: 441 (21 x 21)\n",
      "Games per combination: 1\n",
      "Total games: 441\n",
      "Persona sharing: Enabled\n",
      "Results directory: experiment_results/full_persona_exp_20251118_213336\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Combination 1/441: Codemaster=None, Guesser=None\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Starting collaborative game 0\n",
      "\n",
      "Board State:\n",
      "CZECH | DRILL | TRAIN | ANTARCTICA | UNICORN\n",
      "TAIL | OCTOPUS | COURT | ANGEL | QUEEN\n",
      "DATE | FORCE | BAT | CRICKET | CONCERT\n",
      "NIGHT | PHOENIX | SWING | CAST | KETCHUP\n",
      "BOTTLE | CRASH | LION | FACE | FIGURE\n",
      "\n",
      "\n",
      "=== Turn 1 ===\n",
      "Remaining words to guess: COURT, ANTARCTICA, ANGEL, FACE, TAIL, DATE, CONCERT, DRILL, BAT\n"
     ]
    }
   ],
   "source": [
    "# Import the experiment runner\n",
    "from run_full_experiment import run_full_persona_experiment\n",
    "\n",
    "# ===== EXPERIMENT CONFIGURATION =====\n",
    "config = MODEL_CONFIGS[MODEL_CHOICE]\n",
    "\n",
    "# Number of games per persona combination (default: 5)\n",
    "GAMES_PER_COMBINATION = 1\n",
    "\n",
    "# Whether to enable persona sharing (agents know each other's personas)\n",
    "SHARED_PERSONA = True  # Set to True to enable\n",
    "\n",
    "# Optional: Give this experiment a custom name\n",
    "EXPERIMENT_NAME = None\n",
    "\n",
    "# ===== RUN THE FULL EXPERIMENT =====\n",
    "\n",
    "print(\"⚠️  STARTING FULL EXPERIMENT - This will take a long time!\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Model: {config['model_name']}\")\n",
    "print(f\"  - Games per combination: {GAMES_PER_COMBINATION}\")\n",
    "print(f\"  - Total games: {441 * GAMES_PER_COMBINATION}\")\n",
    "print(f\"  - Persona sharing: {'Enabled' if SHARED_PERSONA else 'Disabled'}\")\n",
    "print(f\"\\nResults will be saved to: experiment_results/\")\n",
    "print(f\"Intermediate results saved after each combination.\\n\")\n",
    "\n",
    "bnch = benchmark.CodeNamesBenchmark()\n",
    "shared_llm_instance = create_llm(config)\n",
    "\n",
    "# Run the experiment\n",
    "full_results = run_full_persona_experiment(\n",
    "    bnch=bnch,\n",
    "    config=config,\n",
    "    shared_llm_instance=shared_llm_instance,\n",
    "    num_games_per_combination=GAMES_PER_COMBINATION,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    shared_persona=SHARED_PERSONA,\n",
    "    results_dir=\"experiment_results\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ EXPERIMENT COMPLETE!\")\n",
    "print(f\"Results saved to: experiment_results/{full_results['experiment_metadata']['experiment_name']}/\")\n",
    "print(f\"Total duration: {full_results['summary_statistics']['total_duration_seconds']/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024e4fe",
   "metadata": {},
   "source": [
    "## Load and Analyze Experiment Results\n",
    "\n",
    "Use these cells to load results from a completed (or in-progress) experiment for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc205ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from a specific experiment\n",
    "from run_full_experiment import load_experiment_results\n",
    "import os\n",
    "\n",
    "# List available experiments\n",
    "results_dir = \"experiment_results\"\n",
    "if os.path.exists(results_dir):\n",
    "    experiments = [d for d in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, d))]\n",
    "    print(\"Available experiments:\")\n",
    "    for i, exp in enumerate(experiments, 1):\n",
    "        print(f\"  {i}. {exp}\")\n",
    "else:\n",
    "    print(\"No experiments found yet.\")\n",
    "    experiments = []\n",
    "\n",
    "# Load a specific experiment (change the experiment name)\n",
    "if experiments:\n",
    "    # Load the most recent experiment\n",
    "    experiment_to_load = experiments[-1]\n",
    "    print(f\"\\nLoading: {experiment_to_load}\")\n",
    "    \n",
    "    loaded_results = load_experiment_results(experiment_to_load, results_dir=results_dir)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nExperiment: {loaded_results['experiment_metadata']['experiment_name']}\")\n",
    "    print(f\"Status: {loaded_results.get('status', 'complete')}\")\n",
    "    print(f\"Combinations completed: {loaded_results['experiment_metadata'].get('combinations_completed', 'N/A')}\")\n",
    "    print(f\"Games completed: {loaded_results['experiment_metadata'].get('games_completed', 'N/A')}\")\n",
    "    \n",
    "    if 'progress' in loaded_results['experiment_metadata']:\n",
    "        progress = loaded_results['experiment_metadata']['progress']\n",
    "        print(f\"Progress: {progress['percent_complete']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nTotal combinations loaded: {len(loaded_results['all_combinations'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis: Extract win rates for all combinations\n",
    "import pandas as pd\n",
    "\n",
    "if experiments and 'all_combinations' in loaded_results:\n",
    "    # Extract summary statistics for each combination\n",
    "    analysis_data = []\n",
    "    \n",
    "    for combo in loaded_results['all_combinations']:\n",
    "        if 'error' not in combo:  # Skip failed combinations\n",
    "            analysis_data.append({\n",
    "                'codemaster_persona': combo.get('codemaster_persona_id') or 'None',\n",
    "                'guesser_persona': combo.get('guesser_persona_id') or 'None',\n",
    "                'win_rate': combo.get('win_rate', 0),\n",
    "                'avg_turns': combo.get('average_turns', 0),\n",
    "                'avg_words_per_clue': combo.get('average_words_per_clue', 0),\n",
    "                'games_played': combo.get('games_played', 0),\n",
    "                'total_correct_guesses': combo.get('total_correct_guesses', 0),\n",
    "                'total_incorrect_guesses': combo.get('total_incorrect_guesses', 0)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(analysis_data)\n",
    "    \n",
    "    print(f\"Loaded {len(df_results)} combinations\")\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Mean win rate: {df_results['win_rate'].mean():.1%}\")\n",
    "    print(f\"  Mean turns per game: {df_results['avg_turns'].mean():.1f}\")\n",
    "    print(f\"  Mean words per clue: {df_results['avg_words_per_clue'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 combinations by win rate:\")\n",
    "    top_10 = df_results.nlargest(10, 'win_rate')[['codemaster_persona', 'guesser_persona', 'win_rate', 'avg_turns']]\n",
    "    print(top_10.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBottom 10 combinations by win rate:\")\n",
    "    bottom_10 = df_results.nsmallest(10, 'win_rate')[['codemaster_persona', 'guesser_persona', 'win_rate', 'avg_turns']]\n",
    "    print(bottom_10.to_string(index=False))\n",
    "    \n",
    "    # Save analysis DataFrame for further use\n",
    "    print(f\"\\n✓ Results DataFrame saved as 'df_results'\")\n",
    "else:\n",
    "    print(\"No experiment results loaded yet. Run the experiment first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396035dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codenames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
